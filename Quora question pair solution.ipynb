{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\programdata\\miniconda3\\envs\\tf\\lib\\site-packages\\gensim\\utils.py:1212: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "import tqdm\n",
    "import pyemd\n",
    "from fuzzywuzzy import fuzz\n",
    "import gensim\n",
    "#import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"import nltk\\nnltk.download('stopwords')\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"import nltk\n",
    "nltk.download('stopwords')\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def read_or_gen_by_list(l):\n",
    "    current = len(l) - 1\n",
    "    if current < 0:\n",
    "        print(\"Error: input list is empty\")\n",
    "        return None\n",
    "    return r_or_g_by_list_n(l, current)\n",
    "\n",
    "def r_or_g_by_list_n(l, i):\n",
    "    name = l[i][0]\n",
    "    func = l[i][1]\n",
    "    path = \"data/{name}.csv\".format(name=name)\n",
    "    if os.path.exists(path):\n",
    "        print(\"read the data for {name}\".format(name=name))\n",
    "        return pd.read_csv(path, sep=\",\")\n",
    "    else:\n",
    "        d = None\n",
    "        print(\"generate the data for {name}\".format(name=name))\n",
    "        if i == 0:\n",
    "            d = func()\n",
    "        else:\n",
    "            parameter = r_or_g_by_list_n(l, i-1)\n",
    "            d = func(parameter)\n",
    "        d.to_csv(path, index=False)\n",
    "        return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "sep = \":\"\n",
    "punctuation = \"\\\"',./:;?[\\]`{}~\"\n",
    "trans_table = str.maketrans('', '', punctuation)\n",
    "\n",
    "print(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def col_gen(data, name, func, target_col=\"question\"):\n",
    "    for i in range(1, 3):\n",
    "        n = \"%s%d\" % (name, i)\n",
    "        question_col = \"%s%d\" % (target_col, i)\n",
    "        data[n] = data[question_col].apply(func)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_feature():\n",
    "    data = pd.read_csv('data/train.csv', sep=',')\n",
    "    data = data.drop(['id', 'qid1', 'qid2'], axis=1)\n",
    "    \n",
    "    data = col_gen(data, 'len', lambda x: len(str(x)))\n",
    "\n",
    "    data = col_gen(data, \"words\", lambda v: sep.join(str(v).translate(trans_table).lower().split()))\n",
    "    data['len_diff'] = (data['len1'] - data['len2']).apply(lambda x: x if x >= 0 else -x)\n",
    "    data = col_gen(data, 'word_len', lambda x: len(str(x).split(sep)), target_col=\"words\")\n",
    "    data['word_len_diff'] = (data['word_len1'] - data['word_len2']).apply(lambda x: x if x>=0 else -x)\n",
    "    \n",
    "    data[\"common_word\"] = data.apply(lambda x: len(\n",
    "        set(str(x['words1']).split(sep)).intersection(\n",
    "            set(str(x['words2']).split(sep)))\n",
    "    ), axis=1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def cal_wmd(row, model):\n",
    "    words1 = [x for x in str(row['words1']).split(sep) if x not in stop_words]\n",
    "    words2 = [x for x in str(row['words2']).split(sep) if x not in stop_words]\n",
    "    return model.wmdistance(words1, words2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wmd_feature(input_data):\n",
    "    print(\"start reading model\")\n",
    "    start = time.time()\n",
    "    model = gensim.models.KeyedVectors.load_word2vec_format(\n",
    "        'data/GoogleNews-vectors-negative300.bin.gz', binary=True)\n",
    "    time_cost = time.time()-start\n",
    "    print(\"model read in {t}s\".format(t=time_cost))\n",
    "    input_data['wmd'] = input_data.apply(lambda x: cal_wmd(x, model), axis=1)\n",
    "    return input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_wmd_feature(input_data):\n",
    "    print(\"start to read and initalize model\")\n",
    "    start = time.time()\n",
    "    norm_model = gensim.models.KeyedVectors.load_word2vec_format(\n",
    "        'data/GoogleNews-vectors-negative300.bin.gz', binary=True)\n",
    "    norm_model.init_sims(replace=True)\n",
    "    time_cost = time.time()-start\n",
    "    print(\"model initialized in {t}s\".format(t=time_cost))\n",
    "    input_data['normal_wmd'] = input_data.apply(lambda x: cal_wmd(x, norm_model), axis=1)\n",
    "    return input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import string\n",
    "\n",
    "def cal_tfidf(corps):\n",
    "    vectorizer = CountVectorizer()\n",
    "    transformer = TfidfTransformer()\n",
    "    tfidf = transformer.fit_transform(vectorizer.fit_transform(corps))\n",
    "    weight = tfidf.toarray()\n",
    "    return weight\n",
    "#cal_tfidf([\"this is an Example\", \"example for an test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_tfidf_for_row(row):\n",
    "    q1 = str(row['words1']).split(sep)\n",
    "    q2 = str(row['words2']).split(sep)\n",
    "    words1 = [x for x in q1 if x not in stop_words]\n",
    "    words2 = [x for x in q2 if x not in stop_words]\n",
    "    corps = None\n",
    "    if len(words1) <= 3 or len(words2) <= 3:\n",
    "        corps = [' '.join(q1), ' '.join(q2)]\n",
    "    else:\n",
    "        corps = [' '.join(words1), ' '.join(words2)]\n",
    "    tfidf = None\n",
    "    try:\n",
    "        tfidf = cal_tfidf(corps)\n",
    "    except BaseException as e:\n",
    "        print(str(e))\n",
    "        print(\"corps:\")\n",
    "        print(corps, row['question1'], row['question2'])\n",
    "        tfidf = [[0, 1], [1, 0]]\n",
    "    return tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine, cityblock, jaccard, canberra, euclidean, minkowski, braycurtis\n",
    "def cal_dists(row):\n",
    "    tfidf = cal_tfidf_for_row(row)\n",
    "    v1 = tfidf[0]\n",
    "    v2 = tfidf[1]\n",
    "    dists = [cosine(v1, v2), euclidean(v1, v2), minkowski(v1, v2), braycurtis(v1, v2)]\n",
    "    return sep.join([str(x) for x in dists])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "funcs = [\"cosine\", \"euclidean\", \"minkowski\", \"braycurtis\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ab(v, index):\n",
    "    print(v)\n",
    "    nv = str(v).split(sep)\n",
    "    print(nv[index])\n",
    "    return float(nv)\n",
    "\n",
    "def abstract_col(col_name, index, input_data):\n",
    "    print(\"to abstract {col}\".format(col=col_name))\n",
    "    input_data[col_name] = input_data['dists'].apply(lambda x: float(str(x).split(sep)[index]))\n",
    "    print(\"{col} is abstracted\".format(col=col_name))\n",
    "    return input_data\n",
    "\n",
    "def cal_dist_all(input_data):\n",
    "    print(\"to calculate basic distance\")\n",
    "    input_data['dists'] = input_data.apply(lambda x: cal_dists(x), axis=1)\n",
    "    print(\"basic distance calculated\")\n",
    "    return input_data\n",
    "    \n",
    "def cal_dist_cols(input_data):\n",
    "    for i, n in enumerate(funcs):\n",
    "        input_data = abstract_col(\"{n}_dist\".format(n=n), int(i), input_data)\n",
    "    return input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuzz_match(input_data):\n",
    "    input_data['qratio'] = input_data.apply(lambda x: fuzz.QRatio(str(x['question1']), \n",
    "                                        str(x['question2'])), axis=1)\n",
    "    print(\"fuzz: qratio finished\")\n",
    "    input_data['wratio'] = input_data.apply(lambda x: fuzz.WRatio(str(x['question1']), \n",
    "                                        str(x['question2'])), axis=1)\n",
    "    print(\"fuzz: wratio finished\")\n",
    "    input_data['partial_ratio'] = input_data.apply(lambda x: fuzz.partial_ratio(str(x['question1']),\n",
    "                                        str(x['question2'])), axis=1)\n",
    "    print(\"fuzz: partial_ratio finished\")\n",
    "    input_data['partial_token_set_ratio'] = input_data.apply(lambda x: fuzz.partial_token_set_ratio(\n",
    "        str(x['question1']), str(x['question2'])), axis=1)\n",
    "    print(\"fuzz: partial_token_set_ratio finished\")\n",
    "    input_data['partial_token_sort_ratio'] = input_data.apply(lambda x: fuzz.partial_token_sort_ratio(\n",
    "        str(x['question1']), str(x['question2'])), axis=1)\n",
    "    print(\"fuzz: partial_token_sort_ratio finished\")\n",
    "    input_data['token_set_ratio'] = input_data.apply(lambda x: fuzz.token_set_ratio(\n",
    "        str(x['question1']), str(x['question2'])), axis=1)\n",
    "    print(\"fuzz: token_set_ratio finished\")\n",
    "    input_data['token_sort_ratio'] = input_data.apply(lambda x: fuzz.token_sort_ratio(\n",
    "        str(x['question1']), str(x['question2'])), axis=1)\n",
    "    print(\"fuzz: token_sort_ratio finished\")\n",
    "    \n",
    "    return input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read the data for match_feature\n"
     ]
    }
   ],
   "source": [
    "operations = [\n",
    "    (\"basic_feature\", basic_feature)\n",
    "    ,(\"dist_base_feature\", cal_dist_all)\n",
    "    ,(\"dist_feature\", cal_dist_cols)\n",
    "    ,(\"add_wmd_feature\", wmd_feature)\n",
    "    ,(\"match_feature\", fuzz_match)\n",
    "    #,(\"add_normal_wmd_feature\", normal_wmd_feature)\n",
    "]\n",
    "features_data = read_or_gen_by_list(operations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>len1</th>\n",
       "      <th>len2</th>\n",
       "      <th>words1</th>\n",
       "      <th>words2</th>\n",
       "      <th>len_diff</th>\n",
       "      <th>word_len1</th>\n",
       "      <th>word_len2</th>\n",
       "      <th>...</th>\n",
       "      <th>minkowski_dist</th>\n",
       "      <th>braycurtis_dist</th>\n",
       "      <th>wmd</th>\n",
       "      <th>qratio</th>\n",
       "      <th>wratio</th>\n",
       "      <th>partial_ratio</th>\n",
       "      <th>partial_token_set_ratio</th>\n",
       "      <th>partial_token_sort_ratio</th>\n",
       "      <th>token_set_ratio</th>\n",
       "      <th>token_sort_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>57</td>\n",
       "      <td>what:is:the:step:by:step:guide:to:invest:in:sh...</td>\n",
       "      <td>what:is:the:step:by:step:guide:to:invest:in:sh...</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>0.457094</td>\n",
       "      <td>0.149261</td>\n",
       "      <td>0.640008</td>\n",
       "      <td>93</td>\n",
       "      <td>95</td>\n",
       "      <td>98</td>\n",
       "      <td>100</td>\n",
       "      <td>89</td>\n",
       "      <td>100</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>88</td>\n",
       "      <td>what:is:the:story:of:kohinoor:(koh-i-noor):dia...</td>\n",
       "      <td>what:would:happen:if:the:indian:government:sto...</td>\n",
       "      <td>37</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>1.085361</td>\n",
       "      <td>0.623300</td>\n",
       "      <td>3.170188</td>\n",
       "      <td>66</td>\n",
       "      <td>86</td>\n",
       "      <td>73</td>\n",
       "      <td>100</td>\n",
       "      <td>75</td>\n",
       "      <td>86</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>59</td>\n",
       "      <td>how:can:i:increase:the:speed:of:my:internet:co...</td>\n",
       "      <td>how:can:internet:speed:be:increased:by:hacking...</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>1.244375</td>\n",
       "      <td>0.725460</td>\n",
       "      <td>1.922139</td>\n",
       "      <td>54</td>\n",
       "      <td>63</td>\n",
       "      <td>53</td>\n",
       "      <td>100</td>\n",
       "      <td>71</td>\n",
       "      <td>66</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           question1  \\\n",
       "0  What is the step by step guide to invest in sh...   \n",
       "1  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2  How can I increase the speed of my internet co...   \n",
       "\n",
       "                                           question2  is_duplicate  len1  \\\n",
       "0  What is the step by step guide to invest in sh...             0    66   \n",
       "1  What would happen if the Indian government sto...             0    51   \n",
       "2  How can Internet speed be increased by hacking...             0    73   \n",
       "\n",
       "   len2                                             words1  \\\n",
       "0    57  what:is:the:step:by:step:guide:to:invest:in:sh...   \n",
       "1    88  what:is:the:story:of:kohinoor:(koh-i-noor):dia...   \n",
       "2    59  how:can:i:increase:the:speed:of:my:internet:co...   \n",
       "\n",
       "                                              words2  len_diff  word_len1  \\\n",
       "0  what:is:the:step:by:step:guide:to:invest:in:sh...         9         14   \n",
       "1  what:would:happen:if:the:indian:government:sto...        37          8   \n",
       "2  how:can:internet:speed:be:increased:by:hacking...        14         14   \n",
       "\n",
       "   word_len2        ...         minkowski_dist  braycurtis_dist       wmd  \\\n",
       "0         12        ...               0.457094         0.149261  0.640008   \n",
       "1         13        ...               1.085361         0.623300  3.170188   \n",
       "2         10        ...               1.244375         0.725460  1.922139   \n",
       "\n",
       "   qratio  wratio  partial_ratio  partial_token_set_ratio  \\\n",
       "0      93      95             98                      100   \n",
       "1      66      86             73                      100   \n",
       "2      54      63             53                      100   \n",
       "\n",
       "   partial_token_sort_ratio  token_set_ratio  token_sort_ratio  \n",
       "0                        89              100                93  \n",
       "1                        75               86                63  \n",
       "2                        71               66                66  \n",
       "\n",
       "[3 rows x 25 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_data[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_columns = ['question1', 'question2', 'is_duplicate', 'len1', 'len2', 'words1', 'words2', 'len_diff', 'word_len1', 'word_len2',\n",
    "               'word_len_diff', 'common_word', 'dists', 'cosine_dist', 'euclidean_dist', 'minkowski_dist', 'braycurtis_dist', 'wmd',\n",
    "        'qratio','wratio','partial_ratio','partial_token_set_ratio','partial_token_sort_ratio','token_set_ratio','token_sort_ratio']\n",
    "feature_columns = ['len1', 'len2', 'len_diff', 'word_len1', 'word_len2', 'word_len_diff', 'common_word', 'cosine_dist',\n",
    "                   'euclidean_dist', 'minkowski_dist', 'braycurtis_dist', 'wmd', 'qratio','wratio','partial_ratio',\n",
    "                   'partial_token_set_ratio','partial_token_sort_ratio','token_set_ratio','token_sort_ratio']\n",
    "features_data = features_data[:30000]\n",
    "input_values = features_data[feature_columns]\n",
    "tag = features_data[\"is_duplicate\"]\n",
    "input_values = input_values.replace([np.inf, -np.inf], 100).fillna(0).astype(np.float64)\n",
    "#input_values = input_values.astype(\"float\")\n",
    "#input_values = input_values.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>len1</th>\n",
       "      <th>len2</th>\n",
       "      <th>len_diff</th>\n",
       "      <th>word_len1</th>\n",
       "      <th>word_len2</th>\n",
       "      <th>word_len_diff</th>\n",
       "      <th>common_word</th>\n",
       "      <th>cosine_dist</th>\n",
       "      <th>euclidean_dist</th>\n",
       "      <th>minkowski_dist</th>\n",
       "      <th>braycurtis_dist</th>\n",
       "      <th>wmd</th>\n",
       "      <th>qratio</th>\n",
       "      <th>wratio</th>\n",
       "      <th>partial_ratio</th>\n",
       "      <th>partial_token_set_ratio</th>\n",
       "      <th>partial_token_sort_ratio</th>\n",
       "      <th>token_set_ratio</th>\n",
       "      <th>token_sort_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13106</th>\n",
       "      <td>60.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.725388</td>\n",
       "      <td>1.204482</td>\n",
       "      <td>1.204482</td>\n",
       "      <td>0.687676</td>\n",
       "      <td>2.098477</td>\n",
       "      <td>51.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2280</th>\n",
       "      <td>113.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.885532</td>\n",
       "      <td>1.330814</td>\n",
       "      <td>1.330814</td>\n",
       "      <td>0.895695</td>\n",
       "      <td>2.970346</td>\n",
       "      <td>42.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11800</th>\n",
       "      <td>152.0</td>\n",
       "      <td>308.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.928654</td>\n",
       "      <td>1.362831</td>\n",
       "      <td>1.362831</td>\n",
       "      <td>0.915282</td>\n",
       "      <td>2.912138</td>\n",
       "      <td>40.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        len1   len2  len_diff  word_len1  word_len2  word_len_diff  \\\n",
       "13106   60.0   36.0      24.0       12.0        8.0            4.0   \n",
       "2280   113.0   48.0      65.0       20.0       10.0           10.0   \n",
       "11800  152.0  308.0     156.0       26.0       58.0           32.0   \n",
       "\n",
       "       common_word  cosine_dist  euclidean_dist  minkowski_dist  \\\n",
       "13106          4.0     0.725388        1.204482        1.204482   \n",
       "2280           2.0     0.885532        1.330814        1.330814   \n",
       "11800          9.0     0.928654        1.362831        1.362831   \n",
       "\n",
       "       braycurtis_dist       wmd  qratio  wratio  partial_ratio  \\\n",
       "13106         0.687676  2.098477    51.0    86.0           58.0   \n",
       "2280          0.895695  2.970346    42.0    86.0           50.0   \n",
       "11800         0.915282  2.912138    40.0    86.0           47.0   \n",
       "\n",
       "       partial_token_set_ratio  partial_token_sort_ratio  token_set_ratio  \\\n",
       "13106                    100.0                      69.0             70.0   \n",
       "2280                     100.0                      49.0             46.0   \n",
       "11800                    100.0                      54.0             52.0   \n",
       "\n",
       "       token_sort_ratio  \n",
       "13106              62.0  \n",
       "2280               41.0  \n",
       "11800              46.0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_values.sample(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(input_values, tag, test_size = 0.2, random_state = 0,\n",
    "                                                    stratify = tag)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0,\n",
    "                                                    stratify = y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def cal_log_loss(y_true, y_pred):\n",
    "    one_hot = OneHotEncoder( sparse=False)\n",
    "    oy_true = one_hot.fit_transform(y_true.reshape(-1, 1))\n",
    "    oy_pred = one_hot.fit_transform(y_pred.reshape(-1, 1))\n",
    "    return log_loss(oy_true, oy_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\programdata\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr_clf = LogisticRegression(solver='lbfgs').fit(X_train, y_train)\n",
    "y_pred = lr_clf.predict(X_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5171800947867298\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "print(fbeta_score(y_val, y_pred, beta=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\programdata\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "d:\\programdata\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "d:\\programdata\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "d:\\programdata\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "d:\\programdata\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "d:\\programdata\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "d:\\programdata\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "d:\\programdata\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "d:\\programdata\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "d:\\programdata\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "d:\\programdata\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "d:\\programdata\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "d:\\programdata\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "d:\\programdata\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "d:\\programdata\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "d:\\programdata\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "d:\\programdata\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "d:\\programdata\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "d:\\programdata\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "d:\\programdata\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "d:\\programdata\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "d:\\programdata\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "d:\\programdata\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "d:\\programdata\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "d:\\programdata\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "d:\\programdata\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "d:\\programdata\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "d:\\programdata\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "d:\\programdata\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "d:\\programdata\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "d:\\programdata\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "d:\\programdata\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "d:\\programdata\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "d:\\programdata\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "d:\\programdata\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\programdata\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "d:\\programdata\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "d:\\programdata\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "d:\\programdata\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "d:\\programdata\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "d:\\programdata\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "d:\\programdata\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "d:\\programdata\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "d:\\programdata\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "d:\\programdata\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "d:\\programdata\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6402144772117963\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=30)\n",
    "parameters = {'criterion': [\"gini\", \"entropy\"], 'max_depth': [10, 30], 'min_samples_split': [0.5, 3],\n",
    "             'min_samples_leaf': [1, 5]}\n",
    "\n",
    "scorer = make_scorer(fbeta_score, beta=0.5)\n",
    "\n",
    "grid_obj = GridSearchCV(clf, param_grid=parameters, scoring=scorer, cv=5)\n",
    "grid_fit = grid_obj.fit(X_train, y_train)\n",
    "\n",
    "best_clf = grid_fit.best_estimator_\n",
    "\n",
    "best_predictions = best_clf.predict(X_val)\n",
    "print(fbeta_score(y_val, best_predictions, beta = 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
