{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "S:\\anaconda\\envs\\tf\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "S:\\anaconda\\envs\\tf\\lib\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read the data for transfered_dist_features_train\n",
      "data for transfered_dist_features_train read\n"
     ]
    }
   ],
   "source": [
    "import features as ft\n",
    "t_data = ft.gen_transfered_dist_feature()[:50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import log_loss\n",
    "import sklearn\n",
    "\n",
    "from scipy.stats import skew, kurtosis\n",
    "from scipy.spatial.distance import cosine, cityblock, jaccard, canberra, euclidean, minkowski, braycurtis\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as pl\n",
    "import matplotlib.patches as mpatches\n",
    "import numpy as np\n",
    "from IPython import get_ipython\n",
    "\n",
    "rand_number = 42\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(y):\n",
    "    oc = OneHotEncoder(categories='auto')\n",
    "    y_r = y.reshape(-1,1)\n",
    "    oc.fit(y_r)\n",
    "    r = oc.transform(y_r).toarray()\n",
    "    return r\n",
    "\n",
    "\n",
    "def get_log_loss(y_true, y_pred):\n",
    "    y_p = one_hot(y_pred)\n",
    "    return log_loss(y_true, y_p)\n",
    "\n",
    "\n",
    "def t_model(gbm):\n",
    "    y_trainp = gbm.predict(X_train)\n",
    "    y_testp  = gbm.predict(X_test)\n",
    "    print(get_log_loss(y_train, y_trainp), get_log_loss(y_test, y_testp))\n",
    "\n",
    "\n",
    "def tt_model(gbm):\n",
    "    gbm = gbm.fit(X_train, y_train)\n",
    "    t_model(gbm)\n",
    "\n",
    "out_features = ['question1', 'question2', 'is_duplicate']\n",
    "features = [x for x in t_data.columns if x not in out_features]\n",
    "\n",
    "t_data = t_data[t_data!=np.inf].dropna()\n",
    "feature_data = t_data.drop_duplicates(features, keep='last')\n",
    "input_data = feature_data[features]\n",
    "input_data = input_data.astype(np.float64)\n",
    "result = feature_data[['is_duplicate']]\n",
    "result = result.values.ravel()\n",
    "\n",
    "def time_cnt(f, tag=\"func\"):\n",
    "    t_start = time()\n",
    "    ret = f()\n",
    "    t_end = time()\n",
    "    t_used = t_end - t_start\n",
    "    print(\"function '%s' use: %f s\" % (tag, t_used))\n",
    "    \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(input_data, result, test_size = 0.2, random_state = 0,\n",
    "                                                    stratify = result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((39809, 164), (9953, 164))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sorted(sklearn.metrics.SCORERS.keys())\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.587422944138884 7.717697046345962\n"
     ]
    }
   ],
   "source": [
    "# base model\n",
    "model = LGBMClassifier(num_thread=8)\n",
    "test_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  45 out of  45 | elapsed:  2.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 20, 'num_leaves': 50} -0.4357211897392911\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "params={\n",
    "    'max_depth': [15, 20, 25, 30, 35],\n",
    "    'num_leaves': [20, 35, 50]\n",
    "}\n",
    "\n",
    "# params = {\n",
    "#               'max_depth': [15, 20, 25, 30, 35],\n",
    "#               'learning_rate': [0.01, 0.02, 0.05, 0.1, 0.15],\n",
    "#               'feature_fraction': [0.6, 0.7, 0.8, 0.9, 0.95],\n",
    "#               'bagging_fraction': [0.6, 0.7, 0.8, 0.9, 0.95],\n",
    "#               'bagging_freq': [2, 4, 5, 6, 8],\n",
    "#               'lambda_l1': [0, 0.1, 0.4, 0.5, 0.6],\n",
    "#               'lambda_l2': [0, 10, 15, 35, 40],\n",
    "#               'cat_smooth': [1, 10, 15, 20, 35]\n",
    "# }\n",
    "gbm = LGBMClassifier(num_thread=8)\n",
    "\n",
    "gsearch1 = GridSearchCV(gbm, param_grid=params, scoring='neg_log_loss', cv=3, verbose=1, n_jobs=3)\n",
    "gsearch1.fit(X_train, y_train)\n",
    "print(gsearch1.best_params_, gsearch1.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.390985639796101 7.502545420053944\n"
     ]
    }
   ],
   "source": [
    "best = LGBMClassifier(num_thread=8, n_jobs=8, max_depth=20, num_leaves=50)\n",
    "tt_model(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done  60 out of  60 | elapsed:  1.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bagging_freq': 20, 'learning_rate': 0.1} -0.4357211897392911\n"
     ]
    }
   ],
   "source": [
    "params={\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2, 0.3],\n",
    "    'bagging_freq': [20, 35, 50, 70]\n",
    "}\n",
    "gbm = LGBMClassifier(n_jobs=8, max_depth=20, num_leaves=50)\n",
    "\n",
    "gsearch1 = GridSearchCV(gbm, param_grid=params, scoring='neg_log_loss', cv=3, verbose=1, n_jobs=3)\n",
    "gsearch1.fit(X_train, y_train)\n",
    "print(gsearch1.best_params_, gsearch1.best_score_)\n",
    "t_model(gsearch1.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  12 out of  12 | elapsed:   18.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bagging_freq': 15} -0.4357211897392911\n",
      "4.390985639796101 7.502545420053944\n"
     ]
    }
   ],
   "source": [
    "params={\n",
    "    'bagging_freq': [15, 10, 5, 2]\n",
    "}\n",
    "gbm = LGBMClassifier(n_jobs=8, max_depth=20, num_leaves=50, learning_rate=0.1)\n",
    "\n",
    "gsearch1 = GridSearchCV(gbm, param_grid=params, scoring='neg_log_loss', cv=3, verbose=1, n_jobs=3)\n",
    "gsearch1.fit(X_train, y_train)\n",
    "print(gsearch1.best_params_, gsearch1.best_score_)\n",
    "t_model(gsearch1.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 25 candidates, totalling 75 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done  75 out of  75 | elapsed:  2.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lambda_l1': 0.4, 'lambda_l2': 10} -0.43348030064365295\n",
      "4.724148747024257 7.426201294595485\n"
     ]
    }
   ],
   "source": [
    "params={\n",
    "    'lambda_l1': [0, 0.1, 0.4, 0.5, 0.6],\n",
    "    'lambda_l2': [0, 10, 15, 35, 40],\n",
    "}\n",
    "gbm = LGBMClassifier(n_jobs=8, max_depth=20, num_leaves=50, learning_rate=0.1)\n",
    "\n",
    "gsearch1 = GridSearchCV(gbm, param_grid=params, scoring='neg_log_loss', cv=3, verbose=1, n_jobs=3)\n",
    "gsearch1.fit(X_train, y_train)\n",
    "print(gsearch1.best_params_, gsearch1.best_score_)\n",
    "t_model(gsearch1.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  36 out of  36 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lambda_l1': 0.3, 'lambda_l2': 8} -0.4330621949635189\n",
      "4.574919438578312 7.297804356324441\n"
     ]
    }
   ],
   "source": [
    "params={\n",
    "    'lambda_l1': [0.33, 0.3, 0.38],\n",
    "    'lambda_l2': [6, 7, 8, 9],\n",
    "}\n",
    "gbm = LGBMClassifier(n_jobs=8, max_depth=20, num_leaves=50, learning_rate=0.1)\n",
    "\n",
    "gsearch1 = GridSearchCV(gbm, param_grid=params, scoring='neg_log_loss', cv=3, verbose=1, n_jobs=3)\n",
    "gsearch1.fit(X_train, y_train)\n",
    "print(gsearch1.best_params_, gsearch1.best_score_)\n",
    "t_model(gsearch1.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 25 candidates, totalling 75 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "S:\\anaconda\\envs\\tf\\lib\\site-packages\\sklearn\\externals\\joblib\\externals\\loky\\process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done  75 out of  75 | elapsed:  2.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bagging_fraction': 0.6, 'feature_fraction': 0.6} -0.43298128261992097\n",
      "4.764058910910964 7.474783919887232\n"
     ]
    }
   ],
   "source": [
    "params={\n",
    "    'feature_fraction': [0.6, 0.7, 0.8, 0.9, 0.95],\n",
    "    'bagging_fraction': [0.6, 0.7, 0.8, 0.9, 0.95],\n",
    "#     'cat_smooth': [1, 10, 15, 20, 35]\n",
    "}\n",
    "gbm = LGBMClassifier(n_jobs=8, max_depth=20, num_leaves=50, learning_rate=0.1, lambda_l1=0.3,lambda_l2=8)\n",
    "\n",
    "gsearch1 = GridSearchCV(gbm, param_grid=params, scoring='neg_log_loss', cv=3, verbose=1, n_jobs=3)\n",
    "gsearch1.fit(X_train, y_train)\n",
    "print(gsearch1.best_params_, gsearch1.best_score_)\n",
    "t_model(gsearch1.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 7 candidates, totalling 21 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  21 out of  21 | elapsed:   48.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cat_smooth': 0.1} -0.4330621949635189\n",
      "4.574919438578312 7.297804356324441\n"
     ]
    }
   ],
   "source": [
    "params={\n",
    "    'cat_smooth': [0.1, 0.3, 0.7, 1, 3, 5, 8]\n",
    "}\n",
    "gbm = LGBMClassifier(n_jobs=8, max_depth=20, num_leaves=50, learning_rate=0.1, lambda_l1=0.3,lambda_l2=8)\n",
    "\n",
    "gsearch1 = GridSearchCV(gbm, param_grid=params, scoring='neg_log_loss', cv=3, verbose=1, n_jobs=3)\n",
    "gsearch1.fit(X_train, y_train)\n",
    "print(gsearch1.best_params_, gsearch1.best_score_)\n",
    "t_model(gsearch1.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
