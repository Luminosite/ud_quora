{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "S:\\anaconda\\envs\\tf\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "S:\\anaconda\\envs\\tf\\lib\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate the data for transfered_dist_features_train\n",
      "generate the data for common_ratio_features_train\n",
      "generate the data for dist_features_train\n",
      "generate the data for norm_wmd_feature_train\n",
      "generate the data for wmd_feature_train\n",
      "generate the data for basic_feature_train\n",
      "basic data is ready\n",
      "function 'clean question string' starts\n",
      "function 'clean question string' use: 1755.320536 s\n",
      "data for basic_feature_train generated\n",
      "data for wmd_feature_train generated\n",
      "data for norm_wmd_feature_train generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "291it [00:00, 2881.19it/s]E:\\quora\\ud_quora\\features.py:180: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return v / np.sqrt((v ** 2).sum())\n",
      "404290it [01:49, 3678.08it/s]\n",
      "404290it [01:52, 3591.05it/s]\n",
      "S:\\anaconda\\envs\\tf\\lib\\site-packages\\scipy\\spatial\\distance.py:702: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n",
      "S:\\anaconda\\envs\\tf\\lib\\site-packages\\scipy\\spatial\\distance.py:1160: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return l1_diff.sum() / l1_sum.sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data for dist_features_train generated\n",
      "data for common_ratio_features_train generated\n",
      "Generate tfidf\n",
      "transfer sparse vec for TruncatedSVD_300\n",
      "prepare features for TruncatedSVD_300\n",
      "transfer sparse vec for TruncatedSVD_25\n",
      "prepare features for TruncatedSVD_25\n",
      "to attach cols: [['q1_TruncatedSVD_25_0', 'q1_TruncatedSVD_25_1', 'q1_TruncatedSVD_25_2', 'q1_TruncatedSVD_25_3', 'q1_TruncatedSVD_25_4', 'q1_TruncatedSVD_25_5', 'q1_TruncatedSVD_25_6', 'q1_TruncatedSVD_25_7', 'q1_TruncatedSVD_25_8', 'q1_TruncatedSVD_25_9', 'q1_TruncatedSVD_25_10', 'q1_TruncatedSVD_25_11', 'q1_TruncatedSVD_25_12', 'q1_TruncatedSVD_25_13', 'q1_TruncatedSVD_25_14', 'q1_TruncatedSVD_25_15', 'q1_TruncatedSVD_25_16', 'q1_TruncatedSVD_25_17', 'q1_TruncatedSVD_25_18', 'q1_TruncatedSVD_25_19', 'q1_TruncatedSVD_25_20', 'q1_TruncatedSVD_25_21', 'q1_TruncatedSVD_25_22', 'q1_TruncatedSVD_25_23', 'q1_TruncatedSVD_25_24'], ['q2_TruncatedSVD_25_0', 'q2_TruncatedSVD_25_1', 'q2_TruncatedSVD_25_2', 'q2_TruncatedSVD_25_3', 'q2_TruncatedSVD_25_4', 'q2_TruncatedSVD_25_5', 'q2_TruncatedSVD_25_6', 'q2_TruncatedSVD_25_7', 'q2_TruncatedSVD_25_8', 'q2_TruncatedSVD_25_9', 'q2_TruncatedSVD_25_10', 'q2_TruncatedSVD_25_11', 'q2_TruncatedSVD_25_12', 'q2_TruncatedSVD_25_13', 'q2_TruncatedSVD_25_14', 'q2_TruncatedSVD_25_15', 'q2_TruncatedSVD_25_16', 'q2_TruncatedSVD_25_17', 'q2_TruncatedSVD_25_18', 'q2_TruncatedSVD_25_19', 'q2_TruncatedSVD_25_20', 'q2_TruncatedSVD_25_21', 'q2_TruncatedSVD_25_22', 'q2_TruncatedSVD_25_23', 'q2_TruncatedSVD_25_24']]\n",
      "transfer sparse vec for NMF_30\n",
      "prepare features for NMF_30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "S:\\anaconda\\envs\\tf\\lib\\site-packages\\scipy\\spatial\\distance.py:702: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to attach cols: [['q1_NMF_30_0', 'q1_NMF_30_1', 'q1_NMF_30_2', 'q1_NMF_30_3', 'q1_NMF_30_4', 'q1_NMF_30_5', 'q1_NMF_30_6', 'q1_NMF_30_7', 'q1_NMF_30_8', 'q1_NMF_30_9', 'q1_NMF_30_10', 'q1_NMF_30_11', 'q1_NMF_30_12', 'q1_NMF_30_13', 'q1_NMF_30_14', 'q1_NMF_30_15', 'q1_NMF_30_16', 'q1_NMF_30_17', 'q1_NMF_30_18', 'q1_NMF_30_19', 'q1_NMF_30_20', 'q1_NMF_30_21', 'q1_NMF_30_22', 'q1_NMF_30_23', 'q1_NMF_30_24', 'q1_NMF_30_25', 'q1_NMF_30_26', 'q1_NMF_30_27', 'q1_NMF_30_28', 'q1_NMF_30_29'], ['q2_NMF_30_0', 'q2_NMF_30_1', 'q2_NMF_30_2', 'q2_NMF_30_3', 'q2_NMF_30_4', 'q2_NMF_30_5', 'q2_NMF_30_6', 'q2_NMF_30_7', 'q2_NMF_30_8', 'q2_NMF_30_9', 'q2_NMF_30_10', 'q2_NMF_30_11', 'q2_NMF_30_12', 'q2_NMF_30_13', 'q2_NMF_30_14', 'q2_NMF_30_15', 'q2_NMF_30_16', 'q2_NMF_30_17', 'q2_NMF_30_18', 'q2_NMF_30_19', 'q2_NMF_30_20', 'q2_NMF_30_21', 'q2_NMF_30_22', 'q2_NMF_30_23', 'q2_NMF_30_24', 'q2_NMF_30_25', 'q2_NMF_30_26', 'q2_NMF_30_27', 'q2_NMF_30_28', 'q2_NMF_30_29']]\n",
      "data for transfered_dist_features_train generated\n"
     ]
    }
   ],
   "source": [
    "import features as ft\n",
    "t_data = ft.gen_transfered_dist_feature()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "from scipy.stats import skew, kurtosis\n",
    "from scipy.spatial.distance import cosine, cityblock, jaccard, canberra, euclidean, minkowski, braycurtis\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "seed = 42\n",
    "rand_number = seed\n",
    "np.random.seed(seed)\n",
    "\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "def one_hot(y):\n",
    "    oc = OneHotEncoder(categories='auto')\n",
    "    y_r = y.reshape(-1,1)\n",
    "    oc.fit(y_r)\n",
    "    r = oc.transform(y_r).toarray()\n",
    "    return r\n",
    "\n",
    "\n",
    "def get_log_loss(y_true, y_pred):\n",
    "    y_p = one_hot(y_pred)\n",
    "    return log_loss(y_true, y_p)\n",
    "\n",
    "\n",
    "def time_cnt(f, tag=\"func\"):\n",
    "    print(\"function '%s' starts\" % tag)\n",
    "    t_start = time()\n",
    "    ret = f()\n",
    "    t_end = time()\n",
    "    t_used = t_end - t_start\n",
    "    print(\"function '%s' use: %f s\" % (tag, t_used))\n",
    "    return ret\n",
    "\n",
    "\n",
    "def prepare_train_set(data, features):\n",
    "    t_data = data[data!=np.inf].dropna()\n",
    "    feature_data = t_data.drop_duplicates(features, keep='last')\n",
    "    input_data = feature_data[features]\n",
    "    input_data = input_data.astype(np.float64)\n",
    "    result = feature_data[['is_duplicate']]\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(input_data, result, test_size = 0.2, random_state = 0,\n",
    "                                                        stratify = result)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "def dist_features_for(data, q1, q2, tag=\"tfidf\"):\n",
    "    q1 = np.nan_to_num(q1)\n",
    "    q2 = np.nan_to_num(q2)\n",
    "\n",
    "    def add_dist_for(func):\n",
    "        col_name = '{d}_distance_{t}'.format(d=func.__name__, t=tag)\n",
    "        data[col_name] = [func(x, y)  for (x, y) in zip(q1, q2)]\n",
    "        return col_name\n",
    "\n",
    "    feats = []\n",
    "    feats .append( add_dist_for(cosine))\n",
    "    feats .append( add_dist_for(cityblock))\n",
    "    feats .append( add_dist_for(jaccard))\n",
    "    feats .append( add_dist_for(canberra))\n",
    "    feats .append( add_dist_for(euclidean))\n",
    "    feats .append( add_dist_for(minkowski))\n",
    "    feats .append( add_dist_for(braycurtis))\n",
    "\n",
    "    data['skew_q1vec_{t}'.format(t=tag)] = [skew(x) for x in q1]\n",
    "    feats .append( 'skew_q1vec_{t}'.format(t=tag))\n",
    "    data['skew_q2vec_{t}'.format(t=tag)] = [skew(x) for x in q2]\n",
    "    feats .append( 'skew_q2vec_{t}'.format(t=tag))\n",
    "    data['kur_q1vec_{t}'.format(t=tag)] = [kurtosis(x) for x in q1]\n",
    "    feats .append( 'kur_q1vec_{t}'.format(t=tag))\n",
    "    data['kur_q2vec_{t}'.format(t=tag)] = [kurtosis(x) for x in q2]\n",
    "    feats .append( 'kur_q2vec_{t}'.format(t=tag))\n",
    "\n",
    "    return data, feats\n",
    "\n",
    "\n",
    "def prepare_vec_dist_train_set(data, vec_gen, tag=\"tag\"):\n",
    "    vec = time_cnt(vec_gen, tag=\"vec gen for %s\" % tag)\n",
    "    single_set_size = int(vec.shape[0]/2)\n",
    "    q1 = vec[:single_set_size]\n",
    "    q2 = vec[single_set_size:]\n",
    "    \n",
    "    print(\"dist features for %s starts to gen\" % tag)\n",
    "    dist_features_data, features = dist_features_for(data, q1, q2, tag=tag)\n",
    "    \n",
    "    print(\"train sets for %s starts to gen\" % tag)\n",
    "    X_train, X_test, y_train, y_test = prepare_train_set(dist_features_data, features)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "def test_data_performace_with_features(data, features):\n",
    "    X_train, X_test, y_train, y_test = prepare_train_set(data, features)\n",
    "    return test_perform_for(X_train, X_test, y_train, y_test)\n",
    "\n",
    "\n",
    "def test_perform_for(X_train, X_test, y_train, y_test):\n",
    "    rf_clf = RandomForestClassifier(random_state=rand_number)\n",
    "    gbdt_clf = GradientBoostingClassifier(random_state=rand_number)\n",
    "    lr_clf = LogisticRegression(random_state=rand_number)\n",
    "    sgd_clf = SGDClassifier(random_state=rand_number)\n",
    "    xgb_clf = XGBClassifier(random_state=rand_number)\n",
    "    lgb_clf = LGBMClassifier(random_state=rand_number)\n",
    "#     models=[(rf_clf, \"RandomForest\"), (gbdt_clf, \"GBDT\"), (lr_clf, \"LogsitcRegression\"), (sgd_clf, \"SGD\"), \n",
    "#             (xgb_clf, \"XGBoost\")] , (lgb_clf, \"lightGBM\")]\n",
    "    models=[(xgb_clf, \"XGBoost\"), (lgb_clf, \"lightGBM\")]\n",
    "\n",
    "    perform = []\n",
    "    for t in models:\n",
    "        model, name = t\n",
    "        t_start = time()\n",
    "        model.fit(X_train, y_train.values.ravel())\n",
    "        t_end = time()\n",
    "        y_predprob = model.predict(X_train)\n",
    "        print(name, \"training time cost:\", (t_end-t_start))\n",
    "        y_t = model.predict(X_test)\n",
    "        res = [get_log_loss(y_train, y_predprob), get_log_loss(y_test, y_t)]\n",
    "        perform.append((name, res))\n",
    "    return perform\n",
    "\n",
    "\n",
    "def tfidf():\n",
    "    ft = ['question1', \"question2\"]\n",
    "    train = t_data.loc[:, ft]\n",
    "    \n",
    "    print('Generate tfidf')\n",
    "    feats= ft\n",
    "    vect_orig = TfidfVectorizer(max_features=None,ngram_range=(1, 1), min_df=3)\n",
    "\n",
    "    corpus = []\n",
    "    for f in feats:\n",
    "        train.loc[:, f] = train.loc[:, f].astype(str)\n",
    "        corpus+=train[f].values.tolist()\n",
    "    vect_orig.fit(corpus)\n",
    "    \n",
    "    train_tfidf = vect_orig.transform(corpus)\n",
    "    return train_tfidf\n",
    "\n",
    "\n",
    "def try_n_for_transfer(transfer, tag=\"svd300\"):\n",
    "    X_train, X_test, y_train, y_test = prepare_vec_dist_train_set(\n",
    "        t_data, lambda: transfer.fit_transform(ti), tag=tag)\n",
    "    performance = test_perform_for(X_train, X_test, y_train, y_test)\n",
    "    return (\"%s performance:\"%tag, performance)\n",
    "    \n",
    "\n",
    "\n",
    "features=[ 'cosine_distance_pca300', 'cityblock_distance_pca300', 'jaccard_distance_pca300',\n",
    "       'canberra_distance_pca300', 'euclidean_distance_pca300', 'minkowski_distance_pca300', 'braycurtis_distance_pca300',\n",
    "       'skew_q1vec_pca300', 'skew_q2vec_pca300', 'kur_q1vec_pca300', 'kur_q2vec_pca300']\n",
    "target_col = \"is_duplicate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate tfidf\n"
     ]
    }
   ],
   "source": [
    "ti = tfidf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function 'vec gen for TruncatedSVD_50'starts\n",
      "function 'vec gen for TruncatedSVD_50' use: 0.780925 s\n",
      "dist features for TruncatedSVD_50 starts to gen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kunfu/miniconda2/envs/tf/lib/python3.5/site-packages/scipy/spatial/distance.py:702: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train sets for TruncatedSVD_50 starts to gen\n",
      "XGBoost training time cost: 0.9808001518249512\n",
      "function 'vec gen for TruncatedSVD_100'starts\n",
      "function 'vec gen for TruncatedSVD_100' use: 1.593821 s\n",
      "dist features for TruncatedSVD_100 starts to gen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kunfu/miniconda2/envs/tf/lib/python3.5/site-packages/scipy/spatial/distance.py:702: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train sets for TruncatedSVD_100 starts to gen\n",
      "XGBoost training time cost: 0.997204065322876\n",
      "function 'vec gen for TruncatedSVD_200'starts\n",
      "function 'vec gen for TruncatedSVD_200' use: 3.320833 s\n",
      "dist features for TruncatedSVD_200 starts to gen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kunfu/miniconda2/envs/tf/lib/python3.5/site-packages/scipy/spatial/distance.py:702: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train sets for TruncatedSVD_200 starts to gen\n",
      "XGBoost training time cost: 0.9678761959075928\n",
      "function 'vec gen for TruncatedSVD_300'starts\n",
      "function 'vec gen for TruncatedSVD_300' use: 5.459460 s\n",
      "dist features for TruncatedSVD_300 starts to gen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kunfu/miniconda2/envs/tf/lib/python3.5/site-packages/scipy/spatial/distance.py:702: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train sets for TruncatedSVD_300 starts to gen\n",
      "XGBoost training time cost: 0.9741940498352051\n",
      "function 'vec gen for NMF_10'starts\n",
      "function 'vec gen for NMF_10' use: 1.315125 s\n",
      "dist features for NMF_10 starts to gen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kunfu/miniconda2/envs/tf/lib/python3.5/site-packages/scipy/spatial/distance.py:702: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train sets for NMF_10 starts to gen\n",
      "XGBoost training time cost: 0.9557170867919922\n",
      "function 'vec gen for NMF_20'starts\n",
      "function 'vec gen for NMF_20' use: 8.124760 s\n",
      "dist features for NMF_20 starts to gen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kunfu/miniconda2/envs/tf/lib/python3.5/site-packages/scipy/spatial/distance.py:702: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train sets for NMF_20 starts to gen\n",
      "XGBoost training time cost: 0.9860780239105225\n",
      "function 'vec gen for NMF_30'starts\n",
      "function 'vec gen for NMF_30' use: 7.182917 s\n",
      "dist features for NMF_30 starts to gen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kunfu/miniconda2/envs/tf/lib/python3.5/site-packages/scipy/spatial/distance.py:702: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train sets for NMF_30 starts to gen\n",
      "XGBoost training time cost: 0.9736499786376953\n",
      "function 'vec gen for LatentDirichletAllocation_10'starts\n",
      "function 'vec gen for LatentDirichletAllocation_10' use: 67.426340 s\n",
      "dist features for LatentDirichletAllocation_10 starts to gen\n",
      "train sets for LatentDirichletAllocation_10 starts to gen\n",
      "XGBoost training time cost: 0.8143031597137451\n",
      "function 'vec gen for LatentDirichletAllocation_20'starts\n",
      "function 'vec gen for LatentDirichletAllocation_20' use: 63.568054 s\n",
      "dist features for LatentDirichletAllocation_20 starts to gen\n",
      "train sets for LatentDirichletAllocation_20 starts to gen\n",
      "XGBoost training time cost: 0.8660018444061279\n",
      "================= result =================\n",
      "TruncatedSVD_50 performance:\t[('XGBoost', [10.379990387737232, 10.94262575153517])]\n",
      "TruncatedSVD_100 performance:\t[('XGBoost', [10.09786930100949, 10.685990880489394])]\n",
      "TruncatedSVD_200 performance:\t[('XGBoost', [9.924485101040071, 10.633894837227968])]\n",
      "TruncatedSVD_300 performance:\t[('XGBoost', [9.742208778814193, 10.384440199625436])]\n",
      "NMF_10 performance:\t[('XGBoost', [11.187939902510804, 11.883620278703015])]\n",
      "NMF_20 performance:\t[('XGBoost', [10.719176449530027, 11.113715665565687])]\n",
      "NMF_30 performance:\t[('XGBoost', [10.781559418557888, 11.135101904819502])]\n",
      "LatentDirichletAllocation_10 performance:\t[('XGBoost', [11.445792972192395, 11.634114154075178])]\n",
      "LatentDirichletAllocation_20 performance:\t[('XGBoost', [11.00307503115586, 11.539254400545003])]\n"
     ]
    }
   ],
   "source": [
    "ms = [\n",
    "      (TruncatedSVD, [50, 100, 200, 300]),\n",
    "      (NMF, [10, 20, 30]),\n",
    "      (LatentDirichletAllocation, [10, 20])\n",
    "     ]\n",
    "reports = []\n",
    "for model_func, n_list in ms:\n",
    "    for n in n_list:\n",
    "        model = model_func(n_components=n)\n",
    "        tag = \"%s_%d\" % (model_func.__name__, n)\n",
    "        reports.append(try_n_for_transfer(model, tag=tag))\n",
    "\n",
    "print(\"================= result =================\")\n",
    "for report in reports:\n",
    "    tags, performances = report\n",
    "    print(\"%s\\t%s\" % (tags, str(performances)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function 'vec gen for NMF_50'starts\n",
      "function 'vec gen for NMF_50' use: 19.773376 s\n",
      "dist features for NMF_50 starts to gen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kunfu/miniconda2/envs/tf/lib/python3.5/site-packages/scipy/spatial/distance.py:702: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train sets for NMF_50 starts to gen\n",
      "XGBoost training time cost: 0.9852018356323242\n",
      "function 'vec gen for NMF_100'starts\n",
      "function 'vec gen for NMF_100' use: 57.651311 s\n",
      "dist features for NMF_100 starts to gen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kunfu/miniconda2/envs/tf/lib/python3.5/site-packages/scipy/spatial/distance.py:702: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train sets for NMF_100 starts to gen\n",
      "XGBoost training time cost: 0.9566638469696045\n",
      "function 'vec gen for NMF_150'starts\n",
      "function 'vec gen for NMF_150' use: 165.686871 s\n",
      "dist features for NMF_150 starts to gen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kunfu/miniconda2/envs/tf/lib/python3.5/site-packages/scipy/spatial/distance.py:702: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train sets for NMF_150 starts to gen\n",
      "XGBoost training time cost: 1.10664701461792\n",
      "================= result =================\n",
      "NMF_50 performance:\t[('XGBoost', [10.483362544757968, 10.721634612579086])]\n",
      "NMF_100 performance:\t[('XGBoost', [10.387119502014524, 10.714505866161147])]\n",
      "NMF_150 performance:\t[('XGBoost', [10.358603044905355, 10.693119626907333])]\n"
     ]
    }
   ],
   "source": [
    "ms = [\n",
    "      (NMF, [50, 100, 150])\n",
    "     ]\n",
    "reports = []\n",
    "for model_func, n_list in ms:\n",
    "    for n in n_list:\n",
    "        model = model_func(n_components=n)\n",
    "        tag = \"%s_%d\" % (model_func.__name__, n)\n",
    "        reports.append(try_n_for_transfer(model, tag=tag))\n",
    "\n",
    "print(\"================= result =================\")\n",
    "for report in reports:\n",
    "    tags, performances = report\n",
    "    print(\"%s\\t%s\" % (tags, str(performances)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function 'vec gen for nmf100'starts\n",
      "function 'vec gen for nmf100' use: 89.899767 s\n",
      "dist features for nmf100 starts to gen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kunfu/miniconda2/envs/tf/lib/python3.5/site-packages/scipy/spatial/distance.py:702: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train sets for nmf100 starts to gen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kunfu/miniconda2/envs/tf/lib/python3.5/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/kunfu/miniconda2/envs/tf/lib/python3.5/site-packages/ipykernel_launcher.py:124: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest training time cost: 0.5205888748168945\n",
      "[0.6379569677730905, 11.432149677556074]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kunfu/miniconda2/envs/tf/lib/python3.5/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBDT training time cost: 1.982990026473999\n",
      "[10.103955327579383, 10.69804031546862]\n",
      "LogsitcRegression training time cost: 0.08344411849975586\n",
      "[11.88595803085617, 11.93105895276114]\n",
      "SGD training time cost: 0.010377168655395508\n",
      "[12.898135566317384, 13.206841242214095]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kunfu/miniconda2/envs/tf/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/kunfu/miniconda2/envs/tf/lib/python3.5/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kunfu/miniconda2/envs/tf/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/Users/kunfu/miniconda2/envs/tf/lib/python3.5/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kunfu/miniconda2/envs/tf/lib/python3.5/site-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/kunfu/miniconda2/envs/tf/lib/python3.5/site-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost training time cost: 1.0862648487091064\n",
      "[10.246515543841523, 10.69804031546862]\n"
     ]
    }
   ],
   "source": [
    "def prepare_vec_dist_train_set(data, vec_gen, tag=\"tag\"):\n",
    "    ms = [\n",
    "          (TruncatedSVD, [50, 100, 200, 300]),\n",
    "          (NMF, [10, 20, 30]),\n",
    "          (LatentDirichletAllocation, [10, 20])\n",
    "         ]\n",
    "    reports = []\n",
    "    for model_func, n_list in ms:\n",
    "        for n in n_list:\n",
    "            model = model_func(n_components=n)\n",
    "            tag = \"%s_%d\" % (model_func.__name__, n)\n",
    "            reports.append(try_n_for_transfer(model, tag=tag))\n",
    "            \n",
    "    vec = time_cnt(vec_gen, tag=\"vec gen for %s\" % tag)\n",
    "    single_set_size = int(vec.shape[0]/2)\n",
    "    q1 = vec[:single_set_size]\n",
    "    q2 = vec[single_set_size:]\n",
    "    \n",
    "    print(\"dist features for %s starts to gen\" % tag)\n",
    "    dist_features_data, features = dist_features_for(data, q1, q2, tag=tag)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_for(data):\n",
    "    ft = ['question1', \"question2\"]\n",
    "    train = data.loc[:, ft]\n",
    "    \n",
    "    feats= ft\n",
    "    vect_orig = TfidfVectorizer(max_features=None,ngram_range=(1, 1), min_df=3)\n",
    "\n",
    "    corpus = []\n",
    "    for f in feats:\n",
    "        train.loc[:, f] = train.loc[:, f].astype(str)\n",
    "        corpus+=train[f].values.tolist()\n",
    "    vect_orig.fit(corpus)\n",
    "    \n",
    "    train_tfidf = vect_orig.transform(corpus)\n",
    "    return train_tfidf\n",
    "\n",
    "\n",
    "\n",
    "def add_vec_features(data, transfer, tag=\"svd300\"):\n",
    "    ti = time_cnt(lambda: tfidf_for(data), tag=\"generate tfidf\")\n",
    "    \n",
    "    vec = time_cnt(lambda: transfer.fit_transform(ti), tag=\"transfer tfidf matrix\")\n",
    "    single_set_size = int(vec.shape[0]/2)\n",
    "    q1 = vec[:single_set_size]\n",
    "    q2 = vec[single_set_size:]\n",
    "    width = int(vec.shape[1])\n",
    "    shortTag = tag.replace(' ', '')\n",
    "    cols = [[\"q{i}_{s}_{sub_num}\".format(i=i, s=shortTag, sub_num=x) for x in range(width)] for i in range(1,3)]\n",
    "    print(cols)\n",
    "    dq1 = pd.DataFrame(q1, columns=cols[0])\n",
    "    dq2 = pd.DataFrame(q2, columns=cols[1])\n",
    "    return pd.concat([data, dq1, dq2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function 'generate tfidf'starts\n",
      "function 'generate tfidf' use: 1.600985 s\n",
      "function 'transfer tfidf matrix'starts\n",
      "function 'transfer tfidf matrix' use: 12.259087 s\n",
      "[['q1_nmf20_0', 'q1_nmf20_1', 'q1_nmf20_2', 'q1_nmf20_3', 'q1_nmf20_4', 'q1_nmf20_5', 'q1_nmf20_6', 'q1_nmf20_7', 'q1_nmf20_8', 'q1_nmf20_9', 'q1_nmf20_10', 'q1_nmf20_11', 'q1_nmf20_12', 'q1_nmf20_13', 'q1_nmf20_14', 'q1_nmf20_15', 'q1_nmf20_16', 'q1_nmf20_17', 'q1_nmf20_18', 'q1_nmf20_19'], ['q2_nmf20_0', 'q2_nmf20_1', 'q2_nmf20_2', 'q2_nmf20_3', 'q2_nmf20_4', 'q2_nmf20_5', 'q2_nmf20_6', 'q2_nmf20_7', 'q2_nmf20_8', 'q2_nmf20_9', 'q2_nmf20_10', 'q2_nmf20_11', 'q2_nmf20_12', 'q2_nmf20_13', 'q2_nmf20_14', 'q2_nmf20_15', 'q2_nmf20_16', 'q2_nmf20_17', 'q2_nmf20_18', 'q2_nmf20_19']]\n"
     ]
    }
   ],
   "source": [
    "n=20\n",
    "model = NMF(n_components=n, init='random', random_state=seed)\n",
    "\n",
    "data = add_vec_features(t_data, model, tag=\"nmf20\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost training time cost: 5.134984493255615\n",
      "lightGBM training time cost: 1.6410515308380127\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('XGBoost', [10.065270578321838, 11.047276808112168]),\n",
       " ('lightGBM', [7.274510357774387, 10.327421996744858])]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_performace_with_features(data, [\n",
    "    'q1_nmf20_0', 'q1_nmf20_1', 'q1_nmf20_2',\n",
    "       'q1_nmf20_3', 'q1_nmf20_4', 'q1_nmf20_5', 'q1_nmf20_6', 'q1_nmf20_7',\n",
    "       'q1_nmf20_8', 'q1_nmf20_9', 'q1_nmf20_10', 'q1_nmf20_11', 'q1_nmf20_12',\n",
    "       'q1_nmf20_13', 'q1_nmf20_14', 'q1_nmf20_15', 'q1_nmf20_16',\n",
    "       'q1_nmf20_17', 'q1_nmf20_18', 'q1_nmf20_19', 'q2_nmf20_0', 'q2_nmf20_1',\n",
    "       'q2_nmf20_2', 'q2_nmf20_3', 'q2_nmf20_4', 'q2_nmf20_5', 'q2_nmf20_6',\n",
    "       'q2_nmf20_7', 'q2_nmf20_8', 'q2_nmf20_9', 'q2_nmf20_10', 'q2_nmf20_11',\n",
    "       'q2_nmf20_12', 'q2_nmf20_13', 'q2_nmf20_14', 'q2_nmf20_15',\n",
    "       'q2_nmf20_16', 'q2_nmf20_17', 'q2_nmf20_18', 'q2_nmf20_19'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['What is the step by step guide to invest in share market in india?',\n",
       "       'What is the story of Kohinoor (Koh-i-Noor) Diamond?',\n",
       "       'How can I increase the speed of my internet connection while using a VPN?',\n",
       "       ...,\n",
       "       \"How can Kaprekar's constant (6174) be proved using MS Excel?\",\n",
       "       'Is Hillary Clinton a dishonest candidate?',\n",
       "       'What is it like to work at a mine in Australia?'], dtype=object)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "t_data['question1'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in range(1,3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"how can kaprekar 's constant ! ( 1=1 ) ( 6174 ) be prove use ms excel ?\""
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = \"How can Kaprekar's constant !(1=1) (6174) be proved using MS Excel?\"\n",
    "def lemmatize_all(sentence):\n",
    "    sentence = sentence.lower()\n",
    "    wnl = nltk.WordNetLemmatizer()\n",
    "    for word, tag in nltk.pos_tag(nltk.word_tokenize(sentence)):\n",
    "        if tag.startswith('NN'):\n",
    "            yield wnl.lemmatize(word, pos='n')\n",
    "        elif tag.startswith('VB'):\n",
    "            yield wnl.lemmatize(word, pos='v')\n",
    "        elif tag.startswith('JJ'):\n",
    "            yield wnl.lemmatize(word, pos='a')\n",
    "        elif tag.startswith('R'):\n",
    "            yield wnl.lemmatize(word, pos='r')\n",
    "        else:\n",
    "            yield word\n",
    "\n",
    "' '.join(lemmatize_all(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>bb</th>\n",
       "      <th>cc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   aa  bb  cc\n",
       "0   1   2   3\n",
       "1   4   5   6\n",
       "2   7   8   9\n",
       "3  11  12  13"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(np.array([\n",
    "    [1,2,3],\n",
    "    [4,5,6],\n",
    "    [7,8,9],\n",
    "    [11,12,13]\n",
    "]), columns=['aa', 'bb', 'cc'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>bb</th>\n",
       "      <th>cc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   aa  bb  cc\n",
       "0   4   2   3\n",
       "1   7   5   6\n",
       "2  10   8   9\n",
       "3  14  12  13"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['aa'] = df['aa'].apply(lambda x: int(x) + 1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Queue\n",
    "import threading\n",
    "import time\n",
    "\n",
    "\n",
    "def run_task(func, index, tag=\"\"):\n",
    "    ret = func()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
