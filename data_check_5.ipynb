{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read the data for common_ratio_features_train\n",
      "data for common_ratio_features_train read\n"
     ]
    }
   ],
   "source": [
    "import features as ft\n",
    "t_data = ft.gen_common_ratio_feature()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from time import time\n",
    "\n",
    "from sklearn.metrics import accuracy_score, fbeta_score, make_scorer, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from scipy.stats import skew, kurtosis\n",
    "from scipy.spatial.distance import cosine, cityblock, jaccard, canberra, euclidean, minkowski, braycurtis\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "seed = 42\n",
    "rand_number = seed\n",
    "np.random.seed(seed)\n",
    "\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.decomposition import TruncatedSVD \n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "\n",
    "def one_hot(y):\n",
    "    oc = OneHotEncoder(categories='auto')\n",
    "    y_r = y.reshape(-1,1)\n",
    "    oc.fit(y_r)\n",
    "    r = oc.transform(y_r).toarray()\n",
    "    return r\n",
    "\n",
    "\n",
    "def get_log_loss(y_true, y_pred):\n",
    "    y_p = one_hot(y_pred)\n",
    "    return log_loss(y_true, y_p)\n",
    "\n",
    "\n",
    "def time_cnt(f, tag=\"func\"):\n",
    "    print(\"function '%s'starts\" % tag)\n",
    "    t_start = time()\n",
    "    ret = f()\n",
    "    t_end = time()\n",
    "    t_used = t_end - t_start\n",
    "    print(\"function '%s' use: %f s\" % (tag, t_used))\n",
    "    return ret\n",
    "\n",
    "\n",
    "def prepare_train_set(data, features):\n",
    "    t_data = data[data!=np.inf].dropna()\n",
    "    feature_data = t_data.drop_duplicates(features, keep='last')\n",
    "    input_data = feature_data[features]\n",
    "    input_data = input_data.astype(np.float64)\n",
    "    result = feature_data[['is_duplicate']]\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(input_data, result, test_size = 0.2, random_state = 0,\n",
    "                                                        stratify = result)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "def dist_features_for(data, q1, q2, tag=\"tfidf\"):\n",
    "    q1 = np.nan_to_num(q1)\n",
    "    q2 = np.nan_to_num(q2)\n",
    "\n",
    "    def add_dist_for(func):\n",
    "        col_name = '{d}_distance_{t}'.format(d=func.__name__, t=tag)\n",
    "        data[col_name] = [func(x, y)  for (x, y) in zip(q1, q2)]\n",
    "        return col_name\n",
    "\n",
    "    feats = []\n",
    "    feats += add_dist_for(cosine)\n",
    "    feats += add_dist_for(cityblock)\n",
    "    feats += add_dist_for(jaccard)\n",
    "    feats += add_dist_for(canberra)\n",
    "    feats += add_dist_for(euclidean)\n",
    "    feats += add_dist_for(minkowski)\n",
    "    feats += add_dist_for(braycurtis)\n",
    "\n",
    "    data['skew_q1vec_{t}'.format(t=tag)] = [skew(x) for x in q1]\n",
    "    feats += 'skew_q1vec_{t}'.format(t=tag)\n",
    "    data['skew_q2vec_{t}'.format(t=tag)] = [skew(x) for x in q2]\n",
    "    feats += 'skew_q2vec_{t}'.format(t=tag)\n",
    "    data['kur_q1vec_{t}'.format(t=tag)] = [kurtosis(x) for x in q1]\n",
    "    feats += 'kur_q1vec_{t}'.format(t=tag)\n",
    "    data['kur_q2vec_{t}'.format(t=tag)] = [kurtosis(x) for x in q2]\n",
    "    feats += 'kur_q2vec_{t}'.format(t=tag)\n",
    "\n",
    "    return data, feats\n",
    "\n",
    "\n",
    "def prepare_vec_dist_train_set(data, vec_gen, tag=\"tag\"):\n",
    "    print(\"vec data %s starts to gen\" % tag)\n",
    "    vec = time_cnt(vec_gen, tag=\"vec gen for %s\" % tag)\n",
    "    single_set_size = int(vec.shape[0]/2)\n",
    "    q1 = vec[:single_set_size]\n",
    "    q2 = vec[single_set_size:]\n",
    "    \n",
    "    print(\"dist features for %s starts to gen\" % tag)\n",
    "    dist_features_data, features = dist_features_for(data, q1, q2, tag=tag)\n",
    "    \n",
    "    print(\"train sets for %s starts to gen\" % tag)\n",
    "    X_train, X_test, y_train, y_test = prepare_train_set(dist_features_data, features)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "def test_perform_for(X_train, X_test, y_train, y_test):\n",
    "    rf_clf = RandomForestClassifier(random_state=rand_number)\n",
    "    gbdt_clf = GradientBoostingClassifier(random_state=rand_number)\n",
    "    lr_clf = LogisticRegression(random_state=rand_number)\n",
    "    sgd_clf = SGDClassifier(random_state=rand_number)\n",
    "    xgb_clf = XGBClassifier(random_state=rand_number)\n",
    "    lgb_clf = LGBMClassifier(random_state=rand_number)\n",
    "    models=[(rf_clf, \"RandomForest\"), (gbdt_clf, \"GBDT\"), (lr_clf, \"LogsitcRegression\"), (sgd_clf, \"SGD\"), \n",
    "            (xgb_clf, \"XGBoost\"), (lgb_clf, \"lightGBM\")]\n",
    "\n",
    "    for t in models:\n",
    "        model, name = t\n",
    "        t_start = time()\n",
    "        model.fit(X_train, y_train)\n",
    "        t_end = time()\n",
    "        y_predprob = model.predict(X_train)\n",
    "        print(name, \"training time cost:\", (t_end-t_start))\n",
    "        y_t = model.predict(X_test)\n",
    "        res = [get_log_loss(y_train, y_predprob), get_log_loss(y_test, y_t)]\n",
    "        print(res)\n",
    "\n",
    "\n",
    "features=[ 'cosine_distance_pca300', 'cityblock_distance_pca300', 'jaccard_distance_pca300',\n",
    "       'canberra_distance_pca300', 'euclidean_distance_pca300', 'minkowski_distance_pca300', 'braycurtis_distance_pca300',\n",
    "       'skew_q1vec_pca300', 'skew_q2vec_pca300', 'kur_q1vec_pca300', 'kur_q2vec_pca300']\n",
    "target_col = \"is_duplicate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = pd.read_pickle(\"train_tfidf.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(808580, 39919)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function 'TSVD300'starts\n",
      "function 'TSVD300' use: 195.672060 s\n"
     ]
    }
   ],
   "source": [
    "pca = TruncatedSVD (n_components =300)\n",
    "pca300 = time_cnt(lambda: pca.fit_transform(tfidf), \"TSVD300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vec data svd200 starts to gen\n",
      "dist features for svd200 starts to gen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "S:\\anaconda\\envs\\tf\\lib\\site-packages\\scipy\\spatial\\distance.py:702: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
     ]
    }
   ],
   "source": [
    "svd200 = TruncatedSVD (n_components =200)\n",
    "X_train, X_test, y_train, y_test = prepare_vec_dist_train_set(t_data, lambda: pca.fit_transform(tfidf), tag=\"svd200\")\n",
    "test_perform_for(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'b']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function 'dist cal'starts\n",
      "function 'dist cal' use: 323.766199 s\n"
     ]
    }
   ],
   "source": [
    "data300 = time_cnt(lambda: dist_features_for(t_data, q1, q2, tag=\"pca300\"), tag=\"dist cal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "S:\\anaconda\\envs\\tf\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "S:\\anaconda\\envs\\tf\\lib\\site-packages\\ipykernel_launcher.py:13: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest training time cost: 13.27211308479309\n",
      "[0.5555409806166707, 10.368125418735417]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "S:\\anaconda\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBDT training time cost: 70.59147572517395\n",
      "[9.954190191819691, 9.963558735729595]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "S:\\anaconda\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "S:\\anaconda\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogsitcRegression training time cost: 4.357003927230835\n",
      "[10.37515913365344, 10.286858748786647]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "S:\\anaconda\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "S:\\anaconda\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD training time cost: 0.3970022201538086\n",
      "[11.271201878041868, 11.18918378522867]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "S:\\anaconda\\envs\\tf\\lib\\site-packages\\sklearn\\preprocessing\\label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "S:\\anaconda\\envs\\tf\\lib\\site-packages\\sklearn\\preprocessing\\label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost training time cost: 33.20322251319885\n",
      "[9.997253244230228, 9.976367069580215]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "S:\\anaconda\\envs\\tf\\lib\\site-packages\\sklearn\\preprocessing\\label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "S:\\anaconda\\envs\\tf\\lib\\site-packages\\sklearn\\preprocessing\\label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lightGBM training time cost: 3.113046884536743\n",
      "[9.608719614308256, 9.73963372668598]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
